{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JoaoMiguel-A01/Projeto_VerificaPDF/blob/main/Conhe%C3%A7a_o_Colab.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import csv\n",
        "import json\n",
        "import re\n",
        "from datetime import datetime\n",
        "import calendar\n",
        "from collections import defaultdict\n",
        "import xml.etree.ElementTree as ET\n",
        "import pandas as pd\n",
        "\n",
        "\n",
        "def associar_pdf_com_xml(pasta_saida, pasta_entrada, caminho_json_xml):\n",
        "    \"\"\"\n",
        "    Associa arquivos PDF aos seus respectivos XMLs com base no número da NF.\n",
        "\n",
        "    Parâmetros:\n",
        "    - pasta_saida: Caminho para o diretório que contém os arquivos XML validados.\n",
        "    - pasta_entrada: Caminho para o diretório que contém os PDFs não validados.\n",
        "    - caminho_json_xml: Caminho para o arquivo JSON com as informações de validação.\n",
        "    \"\"\"\n",
        "\n",
        "    # Obter lista de arquivos XML e PDFs\n",
        "    xml_files = [f for f in os.listdir(pasta_saida) if f.endswith('.xml')]\n",
        "    pdf_files = [f for f in os.listdir(pasta_entrada) if f.endswith('.pdf')]\n",
        "\n",
        "    # Carregar o JSON com os dados das NFs validadas\n",
        "    try:\n",
        "        with open(caminho_json_xml, 'r') as json_file:\n",
        "            dados_json = json.load(json_file)\n",
        "            # Criar um dicionário {numero_nf: chave_nf} a partir do JSON\n",
        "            numero_para_chave_nf = {item['numero_nf']: item['chave_nf'] for item in dados_json}\n",
        "    except FileNotFoundError:\n",
        "        print(\"Erro: Arquivo JSON não encontrado no caminho especificado.\")\n",
        "        return\n",
        "    except KeyError:\n",
        "        print(\"Erro: Estrutura do JSON inválida (faltando 'numero_nf' ou 'chave_nf').\")\n",
        "        return\n",
        "\n",
        "    for xml_file in xml_files:\n",
        "        # Extrair o número da NF do nome do arquivo XML (presente no padrão \"NF-<numero_nf>\")\n",
        "        try:\n",
        "            numero_nf_xml = xml_file.split('-')[-1].replace('.xml', '')\n",
        "        except IndexError:\n",
        "            print(f\"Erro ao extrair o número da NF do XML: {xml_file}\")\n",
        "            continue\n",
        "\n",
        "        # Verificar se o número da NF está no dicionário do JSON\n",
        "        if numero_nf_xml in numero_para_chave_nf:\n",
        "            chave_nf = numero_para_chave_nf[numero_nf_xml]  # Obter a chave de acesso correspondente\n",
        "            # Procurar PDF correspondente pela chave da NF (prefixo do nome do PDF)\n",
        "            pdf_correspondente = next((pdf for pdf in pdf_files if pdf.startswith(chave_nf)), None)\n",
        "\n",
        "            if pdf_correspondente:\n",
        "                # Renomear o arquivo PDF para ter o mesmo nome do XML\n",
        "                origem_pdf = os.path.join(pasta_entrada, pdf_correspondente)\n",
        "                destino_pdf = os.path.join(pasta_saida, f\"{xml_file.replace('.xml', '')}.pdf\")\n",
        "\n",
        "                # Verificar se o arquivo PDF existe antes de tentar renomear\n",
        "                if os.path.exists(origem_pdf):\n",
        "                    os.rename(origem_pdf, destino_pdf)\n",
        "                    print(f\"Associado: {xml_file} ↔ {pdf_correspondente}\")\n",
        "                else:\n",
        "                    print(f\"Erro: Arquivo PDF '{pdf_correspondente}' não encontrado em '{pasta_entrada}'.\")\n",
        "            else:\n",
        "                print(f\"PDF correspondente não encontrado para a chave: {chave_nf}\")\n",
        "        else:\n",
        "            print(f\"Número da NF não encontrado no JSON: {numero_nf_xml}\")\n",
        "\n",
        "\n",
        "\n",
        "# Função para garantir que as pastas existam e informar o usuário\n",
        "def garantir_e_informar_pastas(pasta_entrda, pasta_saida, pasta_nao_corresponde):\n",
        "    # Lista de pastas essenciais\n",
        "    pastas = {\n",
        "        \"Pasta de Entrada (naoValidados)\": pasta_entrada,\n",
        "        \"Pasta de Saída (validados)\": pasta_saida,\n",
        "        \"Pasta de Saída (naoCorresponde)\": pasta_nao_corresponde\n",
        "    }\n",
        "\n",
        "    # Verificar e criar pastas\n",
        "    for nome, caminho in pastas.items():\n",
        "        if not os.path.exists(caminho):  # Se a pasta não existe\n",
        "            os.makedirs(caminho)  # Cria a pasta\n",
        "            print(f\"[INFO] {nome} criada no diretório: {os.path.abspath(caminho)}\")  # Mensagem para o usuário\n",
        "        else:\n",
        "            print(f\"[INFO] {nome} já existe no diretório: {os.path.abspath(caminho)}\")  # Confirma que já existe\n",
        "\n",
        "# Função para remover tudo exceto números\n",
        "def somente_numeros(cnpj):\n",
        "    return re.sub(r'\\D', '', cnpj)\n",
        "\n",
        "# Função para normalizar os dados\n",
        "def normalizar_dado(dado):\n",
        "    if isinstance(dado, str):\n",
        "        return dado.strip().replace(\".\", \"\").replace(\",\", \".\").upper()\n",
        "    return dado\n",
        "\n",
        "# Função para limpar e normalizar os nomes\n",
        "def limpar_nome(nome):\n",
        "    return re.sub(r\"\\s+\", \" \", nome.replace(\"\\n\", \" \").strip())\n",
        "\n",
        "from datetime import datetime\n",
        "\n",
        "def comparar_datas(data_xml, data_planilha, nome_arquivo_xml):\n",
        "    try:\n",
        "        # Verificar se a data do XML está vazia\n",
        "        if not data_xml:\n",
        "            print(f\"[AVISO] A data no XML '{nome_arquivo_xml}' está vazia. Verifique manualmente.\")\n",
        "            return True  # Continua a execução sem validar a data\n",
        "\n",
        "        # Verificar se a data da planilha está vazia\n",
        "        if not data_planilha:\n",
        "            print(f\"[ERRO] A data na planilha está vazia. Verifique os registros.\")\n",
        "            return False\n",
        "\n",
        "        # Converter data do XML\n",
        "        data_formatada_xml = datetime.strptime(data_xml, \"%Y-%m-%d\")  # ISO (aaaa-mm-dd)\n",
        "\n",
        "        # Converter data da planilha com suporte para formatos diferentes\n",
        "        try:\n",
        "            data_formatada_planilha = datetime.strptime(data_planilha, \"%d/%m/%Y\")  # dd/mm/aaaa\n",
        "        except ValueError:\n",
        "            # Tentar com formato de ano abreviado (dd/mm/aa)\n",
        "            data_formatada_planilha = datetime.strptime(data_planilha, \"%d/%m/%y\")  # dd/mm/aa\n",
        "\n",
        "        # Comparar as datas convertidas\n",
        "        return data_formatada_xml == data_formatada_planilha\n",
        "    except ValueError as e:\n",
        "        print(f\"[ERRO] Não foi possível comparar as datas: '{data_xml}' e '{data_planilha}'. Erro: {e}\")\n",
        "        return False  # Retorna falso se houver erro na conversão\n",
        "\n",
        "\n",
        "# Função para converter a planilha em um arquivo JSON\n",
        "def converter_planilha_para_json(caminho_planilha, caminho_json):\n",
        "    # Verificar se o arquivo CSV existe no diretório informado\n",
        "    if not os.path.exists(caminho_planilha):  # Checa se o arquivo existe\n",
        "        print(\"[ERRO] O arquivo CSV especificado não existe no diretório informado.\")\n",
        "        print(\"[DICA] Verifique se o diretório está correto, o nome do arquivo está correto, ou se o arquivo realmente existe.\")\n",
        "        print(\"[INFO] Verifique o problema e tente executar o código novamente.\")\n",
        "        return  # Encerra a execução da função\n",
        "    dados = []\n",
        "    with open(caminho_planilha, mode=\"r\", encoding=\"latin-1\") as arquivo_csv:\n",
        "        leitor = csv.reader(arquivo_csv, delimiter=\";\")\n",
        "        for i, linha in enumerate(leitor, start=1):\n",
        "            if len(linha) < 18:  # Verificar se há colunas suficientes na linha\n",
        "                print(f\"[ERRO] Linha {i} ignorada: número insuficiente de colunas ({len(linha)}).\")\n",
        "                continue\n",
        "            try:\n",
        "                #NF Compra - para cvs com 28 colunas (ainda sem considerar colunas vazias)\n",
        "                if len(linha) == 28:  # Verifica o número de colunas do CSV\n",
        "                #Se o CSV possuir 28 colunas, os dados serão classificados como referentes a uma Nota Fiscal de compra.\n",
        "                    dados.append({\n",
        "                        \"N_PFE\": normalizar_dado(linha[0]),\n",
        "                        \"nome_emissor\": limpar_nome(linha[2]),\n",
        "                        \"uf_emissor\": normalizar_dado(linha[3]),\n",
        "                        \"cnpj_emissor\": normalizar_dado(linha[4]),\n",
        "                        \"nome_destinatario\": limpar_nome(linha[5]),\n",
        "                        \"uf_destinatario\": normalizar_dado(linha[6]),\n",
        "                        \"cnpj_destinatario\": normalizar_dado(linha[7]),\n",
        "                        \"data_vencimento\": normalizar_dado(linha[13]),\n",
        "                        \"quant\": normalizar_dado(linha[14]),\n",
        "                        \"preco_unitario\": normalizar_dado(linha[18]),\n",
        "                        \"valor_total\": normalizar_dado(linha[26]),\n",
        "                        \"cfop\": normalizar_dado(linha[27])\n",
        "                    })\n",
        "                #NF Compra - para cvs com 22 colunas (ainda sem considerar colunas vazias)\n",
        "                elif len(linha) == 22:\n",
        "                #Se o CSV possuir 22 colunas, os dados serão classificados como referentes a uma Nota Fiscal de compra.\n",
        "                    dados.append({\n",
        "                        \"N_PFE\": normalizar_dado(linha[0]),\n",
        "                        \"nome_emissor\": limpar_nome(linha[2]),\n",
        "                        \"uf_emissor\": normalizar_dado(linha[3]),\n",
        "                        \"cnpj_emissor\": normalizar_dado(linha[4]),\n",
        "                        \"nome_destinatario\": limpar_nome(linha[5]),\n",
        "                        \"uf_destinatario\": normalizar_dado(linha[6]),\n",
        "                        \"cnpj_destinatario\": normalizar_dado(linha[7]),\n",
        "                        \"data_vencimento\": normalizar_dado(linha[12]),\n",
        "                        \"quant\": normalizar_dado(linha[13]),\n",
        "                        \"preco_unitario\": normalizar_dado(linha[15]),\n",
        "                        \"valor_total\": normalizar_dado(linha[20]),\n",
        "                        \"cfop\": normalizar_dado(linha[21])\n",
        "                    })\n",
        "                #NF Venda - para cvs com 29 colunas (ainda sem considerar colunas vazias)\n",
        "                elif len(linha) == 29:\n",
        "                #Se o CSV possuir 29 colunas, os dados serão classificados como referentes a uma Nota Fiscal de venda.\n",
        "                    dados.append({\n",
        "                        \"N_PFE\": normalizar_dado(linha[0]),\n",
        "                        \"nome_emissor\": limpar_nome(linha[2]),\n",
        "                        \"uf_emissor\": normalizar_dado(linha[3]),\n",
        "                        \"cnpj_emissor\": normalizar_dado(linha[4]),\n",
        "                        \"nome_destinatario\": limpar_nome(linha[5]),\n",
        "                        \"uf_destinatario\": normalizar_dado(linha[6]),\n",
        "                        \"cnpj_destinatario\": normalizar_dado(linha[7]),\n",
        "                        \"data_vencimento\": normalizar_dado(linha[13]),\n",
        "                        \"quant\": normalizar_dado(linha[14]),\n",
        "                        \"preco_unitario\": normalizar_dado(linha[18]),\n",
        "                        \"valor_total\": normalizar_dado(linha[27]),\n",
        "                        \"cfop\": normalizar_dado(linha[28])\n",
        "                    })\n",
        "                #NF Venda - para cvs com 21 colunas (ainda sem considerar colunas vazias)\n",
        "                else:\n",
        "                    # Mantém o processamento considerando dados de NF de venda.\n",
        "                    dados.append({\n",
        "                        \"N_PFE\": normalizar_dado(linha[0]),\n",
        "                        \"nome_emissor\": limpar_nome(linha[2]),\n",
        "                        \"uf_emissor\": normalizar_dado(linha[3]),\n",
        "                        \"cnpj_emissor\": normalizar_dado(linha[4]),\n",
        "                        \"nome_destinatario\": limpar_nome(linha[5]),\n",
        "                        \"uf_destinatario\": normalizar_dado(linha[6]),\n",
        "                        \"cnpj_destinatario\": normalizar_dado(linha[7]),\n",
        "                        \"data_emissao\": normalizar_dado(linha[9]),\n",
        "                        \"data_vencimento\": normalizar_dado(linha[11]),\n",
        "                        \"quant\": normalizar_dado(linha[12]),\n",
        "                        \"preco_unitario\": normalizar_dado(linha[14]),\n",
        "                        \"valor_total\": normalizar_dado(linha[19]),\n",
        "                        \"cfop\": normalizar_dado(linha[20])\n",
        "                    })\n",
        "            except IndexError as e:\n",
        "                print(f\"[ERRO] Linha {i} com erro: {e}. Conteúdo: {linha}\")\n",
        "\n",
        "    # Salvar os dados extraídos da planilha no formato JSON\n",
        "    with open(caminho_json, \"w\", encoding=\"utf-8\") as json_file:\n",
        "        json.dump(dados, json_file, ensure_ascii=False, indent=4)\n",
        "    print(f\"[INFO] Planilha convertida com sucesso. Dados salvos em {caminho_json}.\")\n",
        "\n",
        "\n",
        "\n",
        "# Função para extrair dados do XMLimport xml.etree.ElementTree as ET\n",
        "def extrair_dados_xml(caminho_xml):\n",
        "    dados = {\n",
        "        \"arquivo_original\": caminho_xml.split(\"/\")[-1],\n",
        "        \"chave_nf\": \"\",\n",
        "        \"nome_emissor\": \"\",\n",
        "        \"data_emissao\": \"\",\n",
        "        \"data_vencimento\": \"\",\n",
        "        \"preco_unitario\": \"\",\n",
        "        \"valor_total\": \"\",\n",
        "        \"uf_destinatário\": \"\",\n",
        "        \"uf_emissor\": \"\",\n",
        "        \"numero_nf\": \"\",\n",
        "        \"cfop\": \"\",\n",
        "        \"quant\": \"\",\n",
        "        \"cnpj_destinatario\": \"\",\n",
        "        \"cnpj_emissor\": \"\"\n",
        "    }\n",
        "\n",
        "    print(f\"[INFO] Processando arquivo XML: {caminho_xml}\")\n",
        "\n",
        "    try:\n",
        "        # Ler e interpretar o arquivo XML\n",
        "        tree = ET.parse(caminho_xml)\n",
        "        root = tree.getroot()\n",
        "\n",
        "        # Obter namespace do XML\n",
        "        namespace = {\"nfe\": \"http://www.portalfiscal.inf.br/nfe\"}\n",
        "\n",
        "        # Capturar Número NF\n",
        "        numero_nf = root.find(\".//nfe:ide/nfe:nNF\", namespace)\n",
        "        if numero_nf is not None:\n",
        "            dados[\"numero_nf\"] = numero_nf.text.strip()\n",
        "        else:\n",
        "            print(\"[DEBUG] Tag  não encontrada.\")\n",
        "\n",
        "        # Capturar Nome do Emitente\n",
        "        nome_emissor = root.find(\".//nfe:emit/nfe:xNome\", namespace)\n",
        "        if nome_emissor is not None:\n",
        "            dados[\"nome_emissor\"] = nome_emissor.text.strip()\n",
        "        else:\n",
        "            print(\"[DEBUG] Tag  não encontrada no emitente.\")\n",
        "\n",
        "        # Capturar CNPJ do Emitente\n",
        "        cnpj_emissor = root.find(\".//nfe:emit/nfe:CNPJ\", namespace)\n",
        "        if cnpj_emissor is not None:\n",
        "            dados[\"cnpj_emissor\"] = cnpj_emissor.text.strip()\n",
        "        else:\n",
        "            print(\"[DEBUG] Tag  não encontrada no emitente.\")\n",
        "\n",
        "        # Capturar Nome do Destinatário\n",
        "        nome_destinatario = root.find(\".//nfe:dest/nfe:xNome\", namespace)\n",
        "        if nome_destinatario is not None:\n",
        "            dados[\"nome_destinatario\"] = nome_destinatario.text.strip()\n",
        "        else:\n",
        "            print(\"[DEBUG] Tag  não encontrada no destinatário.\")\n",
        "\n",
        "        # Capturar CNPJ do Destinatário\n",
        "        cnpj_destinatario = root.find(\".//nfe:dest/nfe:CNPJ\", namespace)\n",
        "        if cnpj_destinatario is not None:\n",
        "            dados[\"cnpj_destinatario\"] = cnpj_destinatario.text.strip()\n",
        "        else:\n",
        "            print(\"[DEBUG] Tag  não encontrada no destinatário.\")\n",
        "\n",
        "        #Capturar Data de Emissão\n",
        "        data_emissao = root.find(\".//nfe:ide/nfe:dhEmi\", namespace)\n",
        "        if data_emissao is not None:\n",
        "            dados[\"data_emissao\"] = data_emissao.text[:10]  # Pega apenas a parte da data (YYYY-MM-DD)\n",
        "        else:\n",
        "            print(\"[DEBUG] Tag  não encontrada.\")\n",
        "\n",
        "        # Capturar Preço Unitário\n",
        "        preco_unitario = root.find(\".//nfe:det/nfe:prod/nfe:vUnCom\", namespace)\n",
        "        if preco_unitario is not None:\n",
        "            dados[\"preco_unitario\"] = preco_unitario.text.strip()\n",
        "        else:\n",
        "            print(\"[DEBUG] Tag <vUnCom> não encontrada.\")\n",
        "\n",
        "        # Capturar Valor Total\n",
        "        valor_total = root.find(\".//nfe:total/nfe:ICMSTot/nfe:vNF\", namespace)\n",
        "        if valor_total is not None:\n",
        "            dados[\"valor_total\"] = valor_total.text.strip()\n",
        "        else:\n",
        "            print(\"[DEBUG] Tag  não encontrada.\")\n",
        "\n",
        "        # Capturar UF do Destinatário\n",
        "        uf = root.find(\".//nfe:dest/nfe:enderDest/nfe:UF\", namespace)\n",
        "        if uf is not None:\n",
        "            dados[\"uf_destinatário\"] = uf.text.strip()\n",
        "        else:\n",
        "            print(\"[DEBUG] Tag  não encontrada no destinatário.\")\n",
        "\n",
        "         # Capturar UF do Emissor\n",
        "        uf = root.find(\".//nfe:emit/nfe:enderEmit/nfe:UF\", namespace)\n",
        "        if uf is not None:\n",
        "            dados[\"uf_emissor\"] = uf.text.strip()\n",
        "        else:\n",
        "            print(\"[DEBUG] Tag  não encontrada no emissor.\")\n",
        "\n",
        "        # Capturar CFOP\n",
        "        cfop = root.find(\".//nfe:det/nfe:prod/nfe:CFOP\", namespace)\n",
        "        if cfop is not None:\n",
        "            dados[\"cfop\"] = cfop.text.strip()\n",
        "        else:\n",
        "            print(\"[DEBUG] Tag  não encontrada.\")\n",
        "\n",
        "        # Capturar Quantidade de Produtos\n",
        "        quant = root.find(\".//nfe:det/nfe:prod/nfe:qCom\", namespace)\n",
        "        if quant is not None:\n",
        "            dados[\"quant\"] = quant.text.strip()\n",
        "        else:\n",
        "            print(\"[DEBUG] Tag  não encontrada.\")\n",
        "\n",
        "        # Capturar Data de Vencimento (se disponível)\n",
        "        data_vencimento = root.find(\".//nfe:cobr/nfe:dup/nfe:dVenc\", namespace)\n",
        "        if data_vencimento is not None:\n",
        "            dados[\"data_vencimento\"] = data_vencimento.text.strip()\n",
        "        else:\n",
        "            print(\"[DEBUG] Tag  não encontrada.\")\n",
        "\n",
        "        # Capturar a chave da NF\n",
        "        inf_nfe = root.find(\".//nfe:infNFe\", namespace)\n",
        "        if inf_nfe is not None:\n",
        "            chave_nf = inf_nfe.attrib.get(\"Id\", \"\")\n",
        "            if chave_nf.startswith(\"NFe\"):\n",
        "                dados[\"chave_nf\"] = chave_nf[3:]  # Remove os três primeiros caracteres \"NFe\"\n",
        "                print(f\"[SUCESSO] Chave NF extraída: {dados['chave_nf']}\")\n",
        "            else:\n",
        "                print(\"[DEBUG] A chave NF não começa com 'NFe'.\")\n",
        "        else:\n",
        "            print(\"[DEBUG] Tag <infNFe> não encontrada.\")\n",
        "\n",
        "    except ET.ParseError as e:\n",
        "        print(f\"[ERRO] Problema ao processar o XML: {e}\")\n",
        "    except Exception as e:\n",
        "        print(f\"[ERRO] Falha ao processar {caminho_xml}: {e}\")\n",
        "\n",
        "    return dados\n",
        "\n",
        "\n",
        "# Função para converter os arquivos XML em um arquivo JSON\n",
        "def converter_xml_para_json(pasta_entrada, caminho_json):\n",
        "    dados_xml = []\n",
        "    for nome_arquivo in os.listdir(pasta_entrada):\n",
        "        if nome_arquivo.endswith(\".xml\"):\n",
        "            caminho_xml = os.path.join(pasta_entrada, nome_arquivo)\n",
        "            dados_xml.append({\n",
        "                \"arquivo_original\": nome_arquivo,  # Guarda o nome original do arquivo\n",
        "                **extrair_dados_xml(caminho_xml)  # Extrai dados e adiciona ao dicionário\n",
        "            })\n",
        "\n",
        "    # Salvar os dados extraídos dos XMLs no formato JSON\n",
        "    with open(caminho_json, \"w\", encoding=\"utf-8\") as json_file:\n",
        "        json.dump(dados_xml, json_file, ensure_ascii=False, indent=4)\n",
        "    print(f\"[INFO] XMLs convertidos com sucesso. Dados salvos em {caminho_json}.\")\n",
        "\n",
        "# Função para carregar dados de um arquivo JSON\n",
        "def carregar_dados_json(caminho_json): # defining the missing function\n",
        "    with open(caminho_json, 'r', encoding='utf-8') as f:\n",
        "        return json.load(f)\n",
        "\n",
        "# Função para validar e renomear arquivos com base nos dados extraídos do XML\n",
        "def validar_e_renomear_arquivos(caminho_json_planilha, caminho_json_xml, pasta_arquivos, pasta_saida, pasta_nao_validados, caminho_txt_relatorio):\n",
        "    if not os.listdir(pasta_entrada):  # Retorna uma lista vazia se a pasta estiver vazia\n",
        "        print(\"[AVISO] A pasta 'naoValidados' está vazia. Por favor, adicione Notas Fiscais em formato XML e execute novamente.\")\n",
        "        return  # Encerra a execução da função\n",
        "    # Carregar dados da planilha e do XML em JSON\n",
        "    dados_planilha = carregar_dados_json(caminho_json_planilha)\n",
        "    dados_xml = carregar_dados_json(caminho_json_xml)\n",
        "    nao_validados = []  # Lista para arquivos não validados\n",
        "    linhas_relatorio = []  # Linhas para o relatório TXT\n",
        "\n",
        "    # Agrupar registros da planilha por CNPJ\n",
        "    registros_por_cnpj = defaultdict(list)\n",
        "    for registro in dados_planilha:\n",
        "        cnpj_destinatario = somente_numeros(registro.get(\"cnpj_destinatario\", \"\"))\n",
        "        cnpj_emissor = somente_numeros(registro.get(\"cnpj_emissor\", \"\"))\n",
        "        if cnpj_destinatario == '17221771000101' or cnpj_destinatario == '39953546000100': #Verifica se o CNPJ é da LIASA ou COMEL\n",
        "            registros_por_cnpj[cnpj_emissor].append(registro)    # NF de compra\n",
        "        else:\n",
        "            registros_por_cnpj[cnpj_destinatario].append(registro) # NF de venda\n",
        "\n",
        "    while dados_xml:\n",
        "        xml_atual = dados_xml.pop(0)  # Pega o primeiro registro XML\n",
        "        arquivo_original = xml_atual.get(\"arquivo_original\", None)\n",
        "        if not arquivo_original:\n",
        "            mensagem = f\"[AVISO] Arquivo original ausente no registro do XML: {xml_atual}\"\n",
        "            print(mensagem)\n",
        "            linhas_relatorio.append(mensagem)\n",
        "            nao_validados.append(xml_atual)\n",
        "            continue\n",
        "        if cnpj_destinatario == '17221771000101' or cnpj_destinatario == '39953546000100': #Verifica se o CNPJ é da LIASA ou COMEL\n",
        "            # NF de compra\n",
        "            cnpj_xml = somente_numeros(xml_atual.get(\"cnpj_emissor\", \"\"))\n",
        "            registros_cnpj = registros_por_cnpj.get(cnpj_xml, [])\n",
        "        else:\n",
        "            # NF de venda\n",
        "            cnpj_xml = somente_numeros(xml_atual.get(\"cnpj_destinatario\", \"\"))\n",
        "            registros_cnpj = registros_por_cnpj.get(cnpj_xml, [])\n",
        "\n",
        "        if not registros_cnpj:\n",
        "            mensagem = f\"[FALHA] Nenhum registro correspondente ao CNPJ do XML: {arquivo_original}\"\n",
        "            print(mensagem)\n",
        "            linhas_relatorio.append(mensagem)\n",
        "            nao_validados.append(xml_atual)\n",
        "            continue\n",
        "\n",
        "        validado = False\n",
        "        melhor_registro = None\n",
        "        menor_diferenca = float(\"inf\")  # Para encontrar o registro mais próximo\n",
        "\n",
        "        # Comparar o XML com os registros do mesmo CNPJ\n",
        "        for registro_planilha in registros_cnpj:\n",
        "            # Comparar os campos\n",
        "            diferencas = [\n",
        "                abs(float(xml_atual.get(\"valor_total\", 0)) - float(registro_planilha.get(\"valor_total\", 0))) <= 0.01,  # Diferença mínima\n",
        "                abs(float(xml_atual.get(\"preco_unitario\", 0)) - float(registro_planilha.get(\"preco_unitario\", 0))) <= 0.01,  # Diferença mínima\n",
        "                float(xml_atual.get(\"quant\", 0)) == float(registro_planilha.get(\"quant\", 0)),\n",
        "                comparar_datas(xml_atual.get(\"data_vencimento\"), registro_planilha.get(\"data_vencimento\"), arquivo_original),\n",
        "                xml_atual.get(\"cfop\") == registro_planilha.get(\"cfop\"),\n",
        "                xml_atual.get(\"uf_destinatario\") == registro_planilha.get(\"uf_destinatario\"),\n",
        "                xml_atual.get(\"uf_emissor\") == registro_planilha.get(\"uf_emissor\")\n",
        "            ]\n",
        "\n",
        "\n",
        "        # Priorizar o registro com menos divergências\n",
        "        total_diferencas = sum(1 for diff in diferencas if not diff)\n",
        "        if total_diferencas < menor_diferenca:\n",
        "            menor_diferenca = total_diferencas\n",
        "            melhor_registro = registro_planilha\n",
        "\n",
        "        # Validar com o melhor registro\n",
        "        if melhor_registro and all(diferencas):  # Exige que TODOS os campos sejam válidos\n",
        "            validado = True\n",
        "        else:\n",
        "            validado = False\n",
        "\n",
        "        # Validar a data de vencimento, ignorando se estiver vazia\n",
        "        data_vencimento = xml_atual.get(\"data_vencimento\", \"\").strip()\n",
        "        if not data_vencimento:\n",
        "            print(f\"[AVISO] A data de vencimento está vazia no arquivo XML '{arquivo_original}'. Verifique manualmente.\")\n",
        "            mes_alfanumerico = \"SEM-MES\"  # Substituto para o caso de ausência de data\n",
        "            mes_referencia = \"SEM-REF\"\n",
        "        else:\n",
        "            try:\n",
        "                data_vencimento = datetime.strptime(data_vencimento, \"%Y-%m-%d\")  # ISO (aaaa-mm-dd)\n",
        "                mes_alfanumerico = f\"{data_vencimento.month:02}{str(data_vencimento.year)[-2:]}\"\n",
        "                mes_referencia = calendar.month_abbr[data_vencimento.month - 1].upper() + str(data_vencimento.year)[-2:]\n",
        "            except ValueError as e:\n",
        "                print(f\"[ERRO] Data de vencimento inválida no arquivo XML '{arquivo_original}': {e}\")\n",
        "                mes_alfanumerico = \"DATA-ERRO\"\n",
        "                mes_referencia = \"DATA-ERRO\"\n",
        "\n",
        "        # Construir novo nome, mesmo em caso de erro e diferenciar NF de compra/venda\n",
        "        cnpj_destinatario = somente_numeros(xml_atual.get(\"cnpj_destinatario\", \"\"))\n",
        "        if cnpj_destinatario == '17221771000101' or cnpj_destinatario == '39953546000100':\n",
        "            # NF de compra (LIASA/COMEL como destinatários)\n",
        "            novo_nome = f\"{mes_alfanumerico}_{melhor_registro['nome_emissor']}_{mes_referencia}_NF-{xml_atual.get('numero_nf', 'SEM-NF')}.xml\"\n",
        "        else:\n",
        "            # NF de venda ou outros casos\n",
        "            novo_nome = f\"{mes_alfanumerico}_{melhor_registro['nome_destinatario']}_{mes_referencia}_NF-{xml_atual.get('numero_nf', 'SEM-NF')}.xml\"\n",
        "\n",
        "\n",
        "\n",
        "        # Renomear e mover o arquivo\n",
        "        caminho_origem = os.path.join(pasta_arquivos, arquivo_original)\n",
        "        caminho_destino = os.path.join(pasta_saida, novo_nome)\n",
        "        print(f\"[DEBUG] Tentando mover arquivo de {caminho_origem} para {caminho_destino}\")\n",
        "        if os.path.exists(caminho_origem):\n",
        "            os.rename(caminho_origem, caminho_destino)\n",
        "            print(f\"[VALIDADO] Arquivo renomeado para: {novo_nome}\")\n",
        "        else:\n",
        "            mensagem = f\"[ERRO] Arquivo XML não encontrado: {arquivo_original}\"\n",
        "            print(mensagem)\n",
        "            linhas_relatorio.append(mensagem)\n",
        "\n",
        "    if not validado:\n",
        "        mensagem = f\"[FALHA] XML não validado: {arquivo_original}\"\n",
        "        print(mensagem)\n",
        "        linhas_relatorio.append(mensagem)\n",
        "\n",
        "        # Log detalhado das divergências\n",
        "        if melhor_registro:\n",
        "            detalhes = f\"[CONFLITO] Comparado com registro errado: {melhor_registro}\"\n",
        "            linhas_relatorio.append(detalhes)\n",
        "\n",
        "        nao_validados.append(xml_atual)\n",
        "\n",
        "\n",
        "    # Gerar arquivo TXT do relatório com mais detalhes relevantes\n",
        "    with open(caminho_txt_relatorio, \"w\", encoding=\"utf-8\") as arquivo_relatorio:\n",
        "        # Escrever mensagens gerais do log\n",
        "        for linha in linhas_relatorio:\n",
        "            arquivo_relatorio.write(linha + \"\\n\")\n",
        "\n",
        "        # Adicionar detalhes específicos das falhas\n",
        "        arquivo_relatorio.write(\"\\n=== Relatório de XMLs Não Validados ===\\n\")\n",
        "        for xml in nao_validados:\n",
        "            arquivo_relatorio.write(f\"\\n[FALHA] XML não validado: {xml.get('arquivo_original', 'Arquivo desconhecido')}\\n\")\n",
        "            print(f\"[FALHA] Comparação falhou para o XML: {xml.get('arquivo_original', 'Arquivo desconhecido')}\")  # Exibir no console\n",
        "\n",
        "            melhor_registro = xml.get(\"melhor_registro\")\n",
        "            if melhor_registro:\n",
        "                arquivo_relatorio.write(\"    Melhor registro encontrado para comparação:\\n\")\n",
        "                arquivo_relatorio.write(f\"      - Nome Destinatário: {melhor_registro.get('nome_destinatario', 'Não encontrado')}\\n\")\n",
        "                arquivo_relatorio.write(f\"      - CNPJ Destinatário: {melhor_registro.get('cnpj_destinatario', 'Não encontrado')}\\n\")\n",
        "                arquivo_relatorio.write(f\"      - Valor Total: {melhor_registro.get('valor_total', 'Não encontrado')}\\n\")\n",
        "\n",
        "                print(f\"    Comparado com o registro da planilha: {melhor_registro}\")  # Exibir no console\n",
        "\n",
        "                # Detalhar campos divergentes\n",
        "                divergencias = []\n",
        "                for campo, valor_xml in xml.get(\"diferencas\", {}).items():\n",
        "                    valor_planilha = melhor_registro.get(campo, \"Não encontrado\")\n",
        "                    if valor_xml != valor_planilha:\n",
        "                        divergencias.append(f\"    - {campo}: XML='{valor_xml}', Planilha='{valor_planilha}'\")\n",
        "                        print(f\"    Divergência no campo '{campo}': XML='{valor_xml}', Planilha='{valor_planilha}'\")  # Exibir no console\n",
        "\n",
        "                if divergencias:\n",
        "                    arquivo_relatorio.write(\"    Detalhes das divergências:\\n\")\n",
        "                    for divergencia in divergencias:\n",
        "                        arquivo_relatorio.write(divergencia + \"\\n\")\n",
        "                else:\n",
        "                    arquivo_relatorio.write(\"    Nenhuma divergência significativa encontrada.\\n\")\n",
        "            else:\n",
        "                arquivo_relatorio.write(\"    Nenhum registro correspondente encontrado na planilha.\\n\")\n",
        "                print(\"    Nenhum registro correspondente encontrado na planilha.\")  # Exibir no console\n",
        "\n",
        "    # Mover XMLs não validados para a pasta separada\n",
        "    for xml in nao_validados:\n",
        "        arquivo_origem = os.path.join(pasta_arquivos, xml.get(\"arquivo_original\", \"\"))\n",
        "        if os.path.exists(arquivo_origem):\n",
        "            destino_nao_validado = os.path.join(pasta_nao_validados, xml.get(\"arquivo_original\", \"\"))\n",
        "            try:\n",
        "                os.rename(arquivo_origem, destino_nao_validado)\n",
        "                print(f\"[NAO VALIDADO] Arquivo movido para a pasta 'naoValidados': {destino_nao_validado}\")\n",
        "            except Exception as e:\n",
        "                print(f\"[ERRO] Não foi possível mover o arquivo '{arquivo_origem}' para '{destino_nao_validado}': {e}\")\n",
        "        else:\n",
        "            mensagem = f\"[ERRO] Arquivo não encontrado para mover: {arquivo_origem}\"\n",
        "            print(mensagem)\n",
        "            linhas_relatorio.append(mensagem)\n",
        "\n",
        "# Configuração principal\n",
        "pasta_entrada = r\"C:\\Users\\joaoconstancio\\Desktop\\VisualStudio\\IdentificaPDF\\naoValidados\"  #Pasta para arquvios nao validados (pasta de entrada)\n",
        "pasta_saida = r\"C:\\Users\\joaoconstancio\\Desktop\\VisualStudio\\IdentificaPDF\\validados\"   #Pasta para arquvios validados (pasta de saida para arquivos renomeados/validados)\n",
        "pasta_nao_corresponde = r\"C:\\Users\\joaoconstancio\\Desktop\\VisualStudio\\IdentificaPDF\\naoCorresponde\"  #Pasta para arquvios que não correspondem com os dados da planilha (pasta de saida para arquivos que não corresponderam com a planilha)\n",
        "caminho_planilha = r\"C:\\Users\\joaoconstancio\\Desktop\\VisualStudio\\IdentificaPDF\\TestePDFCompra-COMEL.csv\" #Caminho para o arquvio csv que será usado como base.\n",
        "caminho_json_planilha = r\"C:\\Users\\joaoconstancio\\Desktop\\VisualStudio\\IdentificaPDF\\dados_planilha.json\" #Altere de acordo com o diretório onde o código for executado.\n",
        "caminho_json_xml = r\"C:\\Users\\joaoconstancio\\Desktop\\VisualStudio\\IdentificaPDF\\dados_xml.json\"  #Altere de acordo com o diretório onde o código for executado.\n",
        "caminho_txt_relatorio = r\"C:\\Users\\joaoconstancio\\Desktop\\VisualStudio\\IdentificaPDF\\relatorio.txt\" #Altere de acordo com o diretório onde o código for executado.\n",
        "\n",
        "# Garantir que as pastas existam\n",
        "#os.makedirs(pasta_xml, exist_ok=True)\n",
        "#os.makedirs(pasta_saida, exist_ok=True)\n",
        "#os.makedirs(pasta_nao_corresponde, exist_ok=True)\n",
        "\n",
        "# Chamadas das funções principais\n",
        "garantir_e_informar_pastas(pasta_entrada, pasta_saida, pasta_nao_corresponde)\n",
        "converter_planilha_para_json(caminho_planilha, caminho_json_planilha)\n",
        "converter_xml_para_json(pasta_entrada, caminho_json_xml)  # Atualizado para converter XML em JSON\n",
        "validar_e_renomear_arquivos(caminho_json_planilha, caminho_json_xml, pasta_entrada, pasta_saida, pasta_nao_corresponde, caminho_txt_relatorio)  # Nova função para XML\n",
        "associar_pdf_com_xml(pasta_saida, pasta_entrada, caminho_json_xml)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Diretórios úteis LIASA\n",
        "#J:\\FATURAS\\2025\\CESSAO\n",
        "#J:\\FATURAS\\2025\\COMPRA\n",
        "#COMEL\n",
        "#J:\\COMEL\\FATURAS\\2025\\COMPRAS\n",
        "#J:\\COMEL\\FATURAS\\2025\\VENDAS"
      ],
      "metadata": {
        "id": "Euh2Q2T2JHMk"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "name": "Conheça o Colab",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}